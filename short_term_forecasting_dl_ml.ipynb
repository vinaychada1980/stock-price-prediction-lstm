{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898796c4",
   "metadata": {},
   "source": [
    "# Short‑Term Trading Forecasts: ML + (Optional) DL\n",
    "\n",
    "This notebook is built for **more accurate** short‑term forecasting using robust, reproducible methods:\n",
    "\n",
    "1. **Data**: Load from CSV **or** download with `yfinance`.\n",
    "2. **Features**: Returns, volatility, lag features, and common technical indicators (SMA/EMA, RSI, MACD, Bollinger Bands, Stochastic Oscillator, ATR, OBV).\n",
    "3. **Validation**: **Walk‑Forward** cross‑validation (time‑series safe splits).\n",
    "4. **Models** (choose any subset):\n",
    "   - Baselines: Naive (last value), Simple Moving Average\n",
    "   - **HistGradientBoostingRegressor** (fast, strong tabular baseline)\n",
    "   - **RandomForestRegressor**\n",
    "   - **Optional Deep Learning**: LSTM (Keras / TensorFlow). If TF isn't installed, skip those cells.\n",
    "5. **Ensembling**: Simple blending of top models.\n",
    "6. **Metrics**: RMSE, MAE, MAPE, **Directional Accuracy**, and a **toy backtest** (long if next‑day return > threshold).\n",
    "\n",
    "**Targets**: Predict next‑day **log return** (safer, stationary). You can switch to price directly if you prefer.\n",
    "\n",
    "**Tip**: Start with ML models; add LSTM once you verify environment has TensorFlow (`pip install tensorflow`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a2441",
   "metadata": {},
   "source": [
    "## 0) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b57d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use yfinance, uncomment the next line in your own environment:\n",
    "# !pip install yfinance ta tensorflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, List, Dict\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa: F401\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For saving models\n",
    "import joblib\n",
    "\n",
    "# Optional deep learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    from tensorflow.keras import layers\n",
    "    TF_AVAILABLE = True\n",
    "except Exception as e:\n",
    "    TF_AVAILABLE = False\n",
    "    print(\"TensorFlow not available; LSTM cells can be skipped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79042f31",
   "metadata": {},
   "source": [
    "## 1) Load Data (CSV or yfinance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd983b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Option A: CSV (recommended for reproducibility) ===\n",
    "# Provide a path to a CSV with at least: Date, Open, High, Low, Close, Volume\n",
    "# The notebook expects 'Date' to be parseable and unique.\n",
    "CSV_PATH = None  # e.g., 'your_prices.csv' or keep None to use yfinance\n",
    "\n",
    "# === Option B: yfinance (requires internet) ===\n",
    "USE_YFINANCE = True\n",
    "TICKER = 'SPY'\n",
    "START = '2015-01-01'\n",
    "END = None  # None = up to latest\n",
    "\n",
    "def load_data(csv_path: Optional[str], use_yf: bool, ticker: str, start: str, end: Optional[str]) -> pd.DataFrame:\n",
    "    if csv_path:\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if 'Date' not in df.columns:\n",
    "            raise ValueError(\"CSV must contain a 'Date' column.\")\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df = df.sort_values('Date')\n",
    "        # Normalize column names\n",
    "        cols = {c.lower(): c for c in df.columns}\n",
    "        # Try to map common names\n",
    "        rename_map = {}\n",
    "        for c in df.columns:\n",
    "            cl = c.lower()\n",
    "            if cl in ['open','high','low','close','adj close','volume']:\n",
    "                rename_map[c] = c.title() if cl != 'adj close' else 'Adj Close'\n",
    "        df = df.rename(columns=rename_map)\n",
    "        # If 'Adj Close' missing, create a copy from 'Close'\n",
    "        if 'Adj Close' not in df.columns and 'Close' in df.columns:\n",
    "            df['Adj Close'] = df['Close']\n",
    "        return df\n",
    "    else:\n",
    "        if not use_yf:\n",
    "            raise ValueError(\"Either provide CSV_PATH or enable USE_YFINANCE.\")\n",
    "        import yfinance as yf\n",
    "        data = yf.download(ticker, start=start, end=end, auto_adjust=False)\n",
    "        data = data.reset_index()\n",
    "        data.rename(columns={'Adj Close': 'Adj Close'}, inplace=True)\n",
    "        return data\n",
    "\n",
    "prices = load_data(CSV_PATH, USE_YFINANCE, TICKER, START, END)\n",
    "assert {'Date','Open','High','Low','Close','Volume'}.issubset(set(prices.columns)), \"Data must have OHLCV columns.\"\n",
    "prices = prices.dropna().reset_index(drop=True)\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb20e16b",
   "metadata": {},
   "source": [
    "## 2) Feature Engineering\n",
    "We build:\n",
    "- Log returns and forward returns (target)\n",
    "- Rolling stats (volatility, mean)\n",
    "- Technical indicators: SMA/EMA, RSI, MACD, Bollinger Bands, Stochastic, ATR, OBV\n",
    "- Lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fda5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df.copy()\n",
    "    d['log_close'] = np.log(d['Adj Close'] if 'Adj Close' in d.columns else d['Close'])\n",
    "    d['ret_1'] = d['log_close'].diff()\n",
    "    d['ret_5'] = d['log_close'].diff(5)\n",
    "    d['ret_10'] = d['log_close'].diff(10)\n",
    "    d['vol_5'] = d['ret_1'].rolling(5).std()\n",
    "    d['vol_10'] = d['ret_1'].rolling(10).std()\n",
    "\n",
    "    # SMA/EMA\n",
    "    for w in [5,10,20,50]:\n",
    "        d[f'sma_{w}'] = d['Close'].rolling(w).mean()\n",
    "        d[f'ema_{w}'] = d['Close'].ewm(span=w, adjust=False).mean()\n",
    "\n",
    "    # Bollinger (20,2)\n",
    "    d['bb_mid'] = d['Close'].rolling(20).mean()\n",
    "    d['bb_std'] = d['Close'].rolling(20).std()\n",
    "    d['bb_up'] = d['bb_mid'] + 2*d['bb_std']\n",
    "    d['bb_dn'] = d['bb_mid'] - 2*d['bb_std']\n",
    "    d['bb_width'] = (d['bb_up'] - d['bb_dn'])/d['bb_mid']\n",
    "\n",
    "    # RSI (14)\n",
    "    delta = d['Close'].diff()\n",
    "    gain = np.where(delta>0, delta, 0.0)\n",
    "    loss = np.where(delta<0, -delta, 0.0)\n",
    "    roll_up = pd.Series(gain).rolling(14).mean()\n",
    "    roll_down = pd.Series(loss).rolling(14).mean()\n",
    "    rs = roll_up / (roll_down + 1e-9)\n",
    "    d['rsi_14'] = 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "    # MACD (12,26,9)\n",
    "    ema12 = d['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = d['Close'].ewm(span=26, adjust=False).mean()\n",
    "    d['macd'] = ema12 - ema26\n",
    "    d['macd_sig'] = d['macd'].ewm(span=9, adjust=False).mean()\n",
    "    d['macd_hist'] = d['macd'] - d['macd_sig']\n",
    "\n",
    "    # Stochastic (14)\n",
    "    low14 = d['Low'].rolling(14).min()\n",
    "    high14 = d['High'].rolling(14).max()\n",
    "    d['stoch_k'] = 100 * (d['Close'] - low14) / (high14 - low14 + 1e-9)\n",
    "    d['stoch_d'] = d['stoch_k'].rolling(3).mean()\n",
    "\n",
    "    # ATR (14)\n",
    "    tr1 = d['High'] - d['Low']\n",
    "    tr2 = (d['High'] - d['Close'].shift()).abs()\n",
    "    tr3 = (d['Low'] - d['Close'].shift()).abs()\n",
    "    tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "    d['atr_14'] = tr.rolling(14).mean()\n",
    "\n",
    "    # OBV\n",
    "    direction = np.sign(d['Close'].diff().fillna(0.0))\n",
    "    d['obv'] = (direction * d['Volume']).cumsum()\n",
    "\n",
    "    # Lags of key signals\n",
    "    for col in ['ret_1','vol_5','vol_10','rsi_14','macd','macd_sig','macd_hist','stoch_k','stoch_d','bb_width','atr_14','obv']:\n",
    "        for lag in [1,2,3,5]:\n",
    "            d[f'{col}_lag{lag}'] = d[col].shift(lag)\n",
    "\n",
    "    # Target: next-day log return\n",
    "    d['y_ret1_ahead'] = d['ret_1'].shift(-1)\n",
    "\n",
    "    d = d.dropna().reset_index(drop=True)\n",
    "    return d\n",
    "\n",
    "feat = add_technical_features(prices)\n",
    "feat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8013deda",
   "metadata": {},
   "source": [
    "## 3) Train / Validation Split (Walk‑Forward CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde838fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the last ~20% as final test; rest for CV\n",
    "split_idx = int(len(feat)*0.8)\n",
    "train_df = feat.iloc[:split_idx].copy()\n",
    "test_df  = feat.iloc[split_idx:].copy()\n",
    "\n",
    "features = [c for c in feat.columns if c not in ['Date','Open','High','Low','Close','Adj Close','Volume','log_close','y_ret1_ahead']]\n",
    "target = 'y_ret1_ahead'\n",
    "\n",
    "X_train, y_train = train_df[features], train_df[target]\n",
    "X_test,  y_test  = test_df[features],  test_df[target]\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b5f68d",
   "metadata": {},
   "source": [
    "## 4) Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6951d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred, label: str):\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = (np.abs((y_true - y_pred) / (y_true + 1e-9))).mean()*100\n",
    "    direction_true = (y_true > 0).astype(int)\n",
    "    direction_pred = (y_pred > 0).astype(int)\n",
    "    dir_acc = (direction_true == direction_pred).mean()\n",
    "    return {'model': label, 'RMSE': rmse, 'MAE': mae, 'MAPE%': mape, 'DirAcc': dir_acc}\n",
    "\n",
    "# Naive baseline: predict today's return as tomorrow's\n",
    "y_pred_naive = train_df['ret_1'].shift(0).reindex(test_df.index).fillna(0.0)  # simple proxy; not leaking future info\n",
    "baseline_naive = evaluate(y_test.values, y_pred_naive.values, 'Naive(ret_t)')\n",
    "\n",
    "# SMA baseline on returns (5-day mean of returns)\n",
    "sma5 = train_df['ret_1'].rolling(5).mean().reindex(test_df.index).fillna(0.0)\n",
    "baseline_sma5 = evaluate(y_test.values, sma5.values, 'SMA(5)_ret')\n",
    "\n",
    "pd.DataFrame([baseline_naive, baseline_sma5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531d0a87",
   "metadata": {},
   "source": [
    "## 5) Strong ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a2e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HistGradientBoosting Regressor\n",
    "hgb = HistGradientBoostingRegressor(random_state=42)\n",
    "param_dist_hgb = {\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'learning_rate': [0.02, 0.05, 0.1],\n",
    "    'max_leaf_nodes': [15, 31, 63, 127],\n",
    "    'min_samples_leaf': [10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "search_hgb = RandomizedSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_distributions=param_dist_hgb,\n",
    "    n_iter=20,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=tscv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "search_hgb.fit(X_train, y_train)\n",
    "best_hgb = search_hgb.best_estimator_\n",
    "y_pred_hgb = best_hgb.predict(X_test)\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestRegressor(random_state=42, n_estimators=500, max_depth=None, min_samples_leaf=50, n_jobs=-1)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [300, 500, 800],\n",
    "    'max_depth': [None, 8, 12],\n",
    "    'min_samples_leaf': [20, 50, 100]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=15,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=tscv,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "search_rf.fit(X_train, y_train)\n",
    "best_rf = search_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "results_ml = pd.DataFrame([\n",
    "    evaluate(y_test.values, y_pred_hgb, 'HistGB'),\n",
    "    evaluate(y_test.values, y_pred_rf,  'RandomForest'),\n",
    "])\n",
    "results_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85869393",
   "metadata": {},
   "source": [
    "## 6) Optional: LSTM (Deep Learning)\n",
    "If TensorFlow is available, we build a compact LSTM over a sliding window of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b67892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 20  # days lookback\n",
    "USE_DL = TF_AVAILABLE\n",
    "\n",
    "def make_sequences(X: pd.DataFrame, y: pd.Series, window: int):\n",
    "    Xv, yv = [], []\n",
    "    arr = X.values.astype(np.float32)\n",
    "    tgt = y.values.astype(np.float32)\n",
    "    for i in range(window, len(X)):\n",
    "        Xv.append(arr[i-window:i, :])\n",
    "        yv.append(tgt[i])\n",
    "    return np.array(Xv), np.array(yv)\n",
    "\n",
    "dl_train_df = train_df.copy()\n",
    "dl_test_df  = test_df.copy()\n",
    "\n",
    "if USE_DL:\n",
    "    scaler = StandardScaler()\n",
    "    Xtr_s = scaler.fit_transform(dl_train_df[features].values)\n",
    "    Xte_s = scaler.transform(dl_test_df[features].values)\n",
    "\n",
    "    Xtr_s = pd.DataFrame(Xtr_s, index=dl_train_df.index, columns=features)\n",
    "    Xte_s = pd.DataFrame(Xte_s, index=dl_test_df.index, columns=features)\n",
    "\n",
    "    Xtr_seq, ytr_seq = make_sequences(Xtr_s, dl_train_df[target], WINDOW)\n",
    "    Xte_seq, yte_seq = make_sequences(pd.concat([Xtr_s.tail(WINDOW), Xte_s]), pd.concat([dl_train_df[target].tail(WINDOW), dl_test_df[target]]), WINDOW)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(WINDOW, len(features))),\n",
    "        layers.LSTM(64, return_sequences=False),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-3), loss='mse')\n",
    "    es = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "    hist = model.fit(\n",
    "        Xtr_seq, ytr_seq,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=[es],\n",
    "        verbose=0\n",
    "    )\n",
    "    y_pred_lstm = model.predict(Xte_seq, verbose=0).ravel()\n",
    "else:\n",
    "    y_pred_lstm = None\n",
    "\n",
    "print(\"LSTM ready\" if y_pred_lstm is not None else \"Skipped LSTM (TensorFlow not installed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198d55a",
   "metadata": {},
   "source": [
    "## 7) Ensembling\n",
    "Blend the two best ML models (and LSTM if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026476c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [y_pred_hgb, y_pred_rf]\n",
    "labels = ['HistGB','RandomForest']\n",
    "\n",
    "if isinstance(y_pred_lstm, np.ndarray):\n",
    "    preds.append(y_pred_lstm)\n",
    "    labels.append('LSTM')\n",
    "\n",
    "# Equal weights by default; you can optimize weights on a validation fold\n",
    "pred_ens = np.mean(np.vstack(preds), axis=0)\n",
    "ens_metrics = evaluate(y_test.values[-len(pred_ens):], pred_ens, 'Ensemble')\n",
    "pd.DataFrame([ens_metrics])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7731d1",
   "metadata": {},
   "source": [
    "## 8) Backtest (Toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple strategy: go long if predicted next-day return > threshold, otherwise stay flat.\n",
    "thr = 0.0005  # 5 bps\n",
    "pred_series = pd.Series(pred_ens, index=y_test.index[-len(pred_ens):], name='pred_ret')\n",
    "true_series = y_test[-len(pred_ens):]\n",
    "\n",
    "signal = (pred_series > thr).astype(int)\n",
    "strategy_ret = signal.shift(1).fillna(0) * true_series  # enter at close, realize next-day\n",
    "cum_pnl = (1 + strategy_ret).cumprod()\n",
    "\n",
    "print('Directional Accuracy:', ((true_series > 0) == (pred_series > 0)).mean())\n",
    "print('Annualized Return (approx):', (cum_pnl.iloc[-1] ** (252/len(cum_pnl)) - 1) if len(cum_pnl) > 0 else np.nan)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "cum_pnl.plot()\n",
    "plt.title('Cumulative Strategy PnL (toy)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Equity Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957383e5",
   "metadata": {},
   "source": [
    "## 9) Save Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56749f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models and scalers\n",
    "joblib.dump(best_hgb, 'model_histgb.joblib')\n",
    "joblib.dump(best_rf, 'model_rf.joblib')\n",
    "\n",
    "# Save last predictions\n",
    "out = pd.DataFrame({\n",
    "    'date': test_df['Date'][-len(pred_ens):].values if 'Date' in test_df.columns else np.arange(len(pred_ens)),\n",
    "    'y_true': y_test[-len(pred_ens):].values,\n",
    "    'y_pred_ensemble': pred_ens\n",
    "})\n",
    "out.to_csv('predictions.csv', index=False)\n",
    "print('Saved: model_histgb.joblib, model_rf.joblib, predictions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7364d592",
   "metadata": {},
   "source": [
    "## 10) How to Use on Your Data\n",
    "1. Put your OHLCV data in a CSV with columns: `Date, Open, High, Low, Close, Volume` (optional `Adj Close`).\n",
    "2. Set `CSV_PATH = 'your_file.csv'` and `USE_YFINANCE = False`.\n",
    "3. Run all cells. The notebook will feature‑engineer, CV‑tune, evaluate, ensemble, and backtest.\n",
    "4. Inspect `predictions.csv` and the printed metrics.\n",
    "\n",
    "**Notes for best accuracy**:\n",
    "- Stick to **returns** as the target (more stationary) and predict shorter horizons (1–5 days).\n",
    "- Keep **walk‑forward** validation to avoid look‑ahead bias.\n",
    "- Regularize heavily (larger `min_samples_leaf`, smaller learning rate) to reduce overfit.\n",
    "- Try adding **calendar** features (weekday, month), macro factors, and **market regime** indicators (VIX, rates) if available.\n",
    "- If using LSTM, standardize inputs and experiment with input windows (e.g., 20–60 days)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
